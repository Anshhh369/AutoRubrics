def example():
  context = """ 
  
  What Makes a Good Rubric ?

  The rubric plays a critical role in automating the assignment evaluation process by providing a structured framework that guides the development of algorithms and assessment criteria. Here’s how the rubric simplifies and enhances the automation process:
  
  1. Clear Criteria for Evaluation
  
  A well-defined rubric lays out specific criteria for each aspect of the assignment, which can be translated into measurable, objective components for automation. This includes:
  
  Keywords and Concepts: Identifying specific keywords, phrases, and concepts that need to be present in student responses. Automation tools can be programmed to search for these indicators as proof of meeting the rubric's requirements.
  Quality Indicators: Defining what makes a good response, such as depth of analysis, relevance, accuracy, and coherence. These can be quantified and assessed using natural language processing techniques.
  2. Consistent Scoring
  
  The rubric provides a consistent scoring system that can be directly implemented into an automated grading system, ensuring that:
  
  Uniformity: Every student’s work is evaluated against the same standards, promoting fairness and consistency in grading.
  Scalability: With consistent scoring guidelines, it becomes feasible to scale the evaluation process for large classes or across multiple sections without a loss in grading quality.
  3. Detailed Feedback Mechanisms
  
  Rubrics often break down the grading criteria into specific, detailed components. This level of detail can be utilized to generate targeted feedback for students, where the system:
  
  Identifies Gaps: Automatically detects areas where the student's submission does not meet the rubric criteria and provides specific feedback on how to improve.
  Highlights Strengths: Recognizes parts of the assignment that excel according to the rubric standards and informs students of their strengths.
  4. Guidance for Development of Algorithms
  
  The specifics in a rubric guide the development of algorithms for automated evaluation:
  
  Text Analysis Algorithms: Rubrics can dictate the type of text analysis needed, whether it's simple keyword detection, semantic analysis for understanding context, or syntactic analysis for writing quality.
  Custom Machine Learning Models: If advanced assessment is needed (like evaluating creative insights or complex argumentation), rubrics can guide the training of machine learning models by providing examples of high and low-scoring responses.
  5. Benchmarking and Calibration
  
  Rubrics serve as a benchmark for calibrating the automated system’s performance:
  
  Testing and Refinement: Automated grading systems can be tested against the rubric to ensure they align with human judgment. Discrepancies can be used to refine the system.
  Continuous Improvement: As assignments and educational standards evolve, rubrics can be updated, and the automated systems can be re-calibrated to match these changes, ensuring the technology remains up-to-date with educational practices.
  6. Legal and Ethical Compliance
  
  By automating based on an established rubric, educational institutions can better defend the fairness and transparency of their grading systems, which is crucial for compliance with educational standards and regulations.
  
  In summary, rubrics not only provide the foundational structure necessary for automating assignment evaluations but also ensure that automation enhances educational outcomes without compromising on quality or fairness. They serve as a bridge between educational objectives and technological capabilities, making them indispensable in the process of automation.
  
  Can you give me an example of a rubric that adheres to all these above mentioned standards vs one that does not. I can give you a sample assignment to use as a reference.
  
  Assignment Title: Understanding Prompt Engineering
  
  Objective:
  
  The objective of this assignment is to help students grasp the concept of prompt engineering in the context of natural language processing and demonstrate their understanding through a motivating example.
  
  Instructions:
  
  Part 1: Explain Prompt Engineering (roughly 300-400 words)
  
  In this part of the assignment, you are required to provide a comprehensive explanation of what prompt engineering is and why it is important in the field of natural language processing and machine learning. Your explanation should cover the following points:
  
  Define Prompt Engineering: Begin by defining prompt engineering in your own words. Explain its purpose and significance. Part 2: Create a Motivating Example (200-250 words)
  
  In this part of the assignment, you will provide a motivating example that illustrates the concept of prompt engineering. Your example should demonstrate how different prompts can lead to distinct outcomes when interacting with a language model. Consider the following:
  
  Choose a scenario: Select a specific scenario or task where language models can be applied, such as a chatbot, question-answering system, or language translation. Craft two or more prompts: Create at least two distinct prompts that guide the language model to generate responses related to the chosen scenario. Show the contrast: Present the responses generated by the language model for each of the prompts and explain the differences in the output. Reflect on the impact: Discuss how prompt engineering influenced the outcomes in your example and why one prompt may have been more effective or appropriate than the others.
  
  Let's construct two examples of rubrics for the assignment titled "Understanding Prompt Engineering." One will adhere to the standards of clarity, consistency, detailed feedback mechanisms, guidance for algorithms, benchmarking, and ethical compliance, while the other will not.
  
  Effective Rubric
  
  Total Points: 100
  
  Part 1: Explanation of Prompt Engineering (50 Points)
  
  45-50 Points: Provides a clear, concise definition of prompt engineering in student's own words. Explanation comprehensively covers its purpose and significance in the context of NLP and ML. Includes examples and is free from factual errors.
  35-44 Points: Definition and explanation are generally clear but may lack some detail or clarity in the significance in NLP and ML. Minor factual inaccuracies may be present.
  20-34 Points: Provides a basic definition but lacks detail and significant discussion on its importance. Some factual errors are present.
  0-19 Points: The explanation is unclear or incorrect, with major factual errors and omissions in defining prompt engineering.
  Part 2: Creating a Motivating Example (50 Points)
  
  45-50 Points: Provides a detailed scenario with at least two distinct, well-crafted prompts. Demonstrates a clear understanding of how different prompts lead to different outcomes. Responses are analyzed thoroughly, showing how prompt engineering influenced the results.
  35-44 Points: Scenario and prompts are appropriate but lack some detail or creativity. The comparison of outcomes is present but lacks depth in analysis or significance.
  20-34 Points: Scenario is given, but prompts are not clearly distinct or well explained. Minimal analysis of the outcomes.
  0-19 Points: Fails to provide a relevant scenario or clear prompts. No effective analysis of the outcomes.
  Feedback Guidelines:
  
  Specific comments should be provided for each part, noting where the student excelled or lacked.
  Suggestions for improvement and further reading should be given, especially where students struggle to explain or demonstrate the concepts effectively.
  Ineffective Rubric
  
  Total Points: 100
  
  Part 1: Explanation of Prompt Engineering (50 Points)
  
  Excellent: Good job.
  Good: Satisfactory work.
  Fair: Could be better.
  Poor: Not acceptable.
  Part 2: Creating a Motivating Example (50 Points)
  
  Excellent: Very creative.
  Good: Some creativity.
  Fair: Not very creative.
  Poor: Lacking creativity.
  Feedback Guidelines:
  
  Generic comments like "good job" or "needs improvement" without specific details.
  Analysis
  
  The effective rubric:
  
  Adheres to standards: It offers clear, measurable, and detailed criteria for each part of the assignment, allowing for consistency and fairness in grading.
  Supports automation: Detailed levels of performance make it possible to develop algorithms that can automatically detect key phrases, depth of analysis, and clarity of expression.
  Provides detailed feedback: It helps students understand exactly what they did well and what they need to improve.
  The ineffective rubric:
  
  Lacks specificity: It uses vague descriptors that do not convey specific standards or expectations, leading to subjective grading.
  Difficult to automate: Lacks clear metrics that could be quantified or automatically assessed.
  Non-informative feedback: Fails to provide actionable feedback that would help students improve their understanding or performance.
  This comparison highlights how a well-structured rubric not only facilitates fair and effective grading but also supports the potential automation of the grading process, providing clear benefits in educational settings.
  
  What do you think about the following rubric for the same assignment "Assignment 1" in the context of making it helpful to automate the assignment grading process ?
  
  Assignment 1 grading criteria: Part 1 - 2 points (give this to everyone) Part 2 - Create Motivating Example a) For choosing motivating scenario - 1 points b) Two distinct prompts - 2 points if screenshot attached - 1 point c) difference between 2 prompts and explanation - 2 points d) explanation of Impact - 2 points
  
  The rubric you provided for "Assignment 1" has several elements that are advantageous for automating the grading process, but it also has areas that could be improved to enhance consistency, clarity, and depth of evaluation. Here's a breakdown of its strengths and areas for improvement:
  
  Strengths of the Current Rubric:
  
  Simplicity and Clarity: The rubric is straightforward and clear about what is expected for each part. It defines specific, measurable actions like "choosing a motivating scenario," "attaching a screenshot," and creating "two distinct prompts."
  
  Objective Criteria: It includes objective criteria such as the requirement for screenshots and the number of prompts, which are easily verifiable in an automated system.
  
  Areas for Improvement:
  
  Granularity and Detail:
  
  Part 1 offers very limited information on what constitutes adequate content to earn the full points. Giving everyone 2 points regardless of the quality or completeness of their explanation can undermine the educational value of the assignment and doesn't encourage thorough understanding or effort.
  Part 2 (d) Explanation of Impact: While it is allotted 2 points, the rubric doesn't specify what makes for a sufficient vs. excellent explanation of impact. This could lead to subjective interpretations unless more detailed criteria are provided.
  Depth of Criteria:
  
  The rubric could benefit from more detailed descriptors that explain what constitutes a quality scenario, what makes prompts distinct, and how effectively differences and impacts should be explained. This detail will aid not only in more consistent grading but also in providing meaningful feedback to students.
  Incentivizing Higher-Quality Responses:
  
  The current rubric does not differentiate adequately between basic compliance with assignment instructions and more thoughtful, insightful responses. It may encourage minimal effort just to meet the basic criteria without pushing for deeper engagement or creativity.
  Feedback Mechanism:
  
  There is no indication of how feedback will be given based on the scores. For an automated system, integrating specific feedback based on the rubric's points could guide students on how to improve their submissions in future assignments.
  Suggestions for Improvement:
  
  To make this rubric more effective, especially in the context of automated grading, consider the following adjustments:
  
  Expand on Part 1: Define what a comprehensive explanation should include. Perhaps set criteria based on the presence of key terms, the depth of explanation, and the inclusion of examples or citations.
  
  Enhance Detail in Part 2:
  
  (a) Describe what a "motivating scenario" should entail. For example, scenarios should be realistic, relevant to prompt engineering, and clearly link to the application of language models.
  (b) Clarify what makes prompts "distinct"—they should lead to noticeably different outcomes or demonstrate different applications of the same model.
  (c) Require that the difference in prompts is not only identified but also analyzed for why those differences lead to varied outputs.
  (d) Include criteria for a high-quality explanation of impact, such as demonstrating understanding of prompt engineering principles and their practical implications.
  Implement a Scoring Scale with Descriptors: Instead of flat points, use a scale (e.g., 0-2 for each section) where 0 indicates non-compliance, 1 indicates basic compliance, and 2 reflects exceeding expectations with detailed, insightful contributions.
  
  By refining the rubric in these ways, you can enhance its utility for automated grading systems while also providing a more effective educational tool that encourages and rewards deeper student engagement and learning.
  
  
  
  Examples:-
  
  Example 1:
  Here’s the expanded and detailed rubric for the assignment on writing a chapter on Generative AI using Prompt Engineering, with in-depth descriptions for each section, particularly focusing on "Process Documentation and Evaluation of Prompt Techniques" and "Originality and Insight":
  
  Total Points: 100
  Content and Relevance: 20 points
  Organization and Structure: 15 points
  Use of Prompt Engineering: 15 points
  Writing Quality: 15 points
  Originality and Insight: 10 points
  Process Documentation and Evaluation of Prompt Techniques: 25 points
  
  Detailed Rubric:
  1. Content and Relevance (20 Points)
  17-20 Points: Comprehensive, in-depth research that is highly relevant and enhances understanding significantly.
  13-16 Points: Solid research effort, relevant and informative, though some areas could be more detailed.
  8-12 Points: Adequate research with some relevant information, includes minor irrelevant details.
  0-7 Points: Insufficient depth, with many irrelevant sections.
  
  2. Organization and Structure (15 Points)
  13-15 Points: Exceptionally well-organized; logical flow enhances comprehension and adherence to the outline.
  10-12 Points: Well-organized, minor deviations from the ideal structure.
  5-9 Points: Some organizational issues; structure affects clarity.
  0-4 Points: Poor organization; significantly impacts readability.
  
  3. Use of Prompt Engineering (15 Points)
  13-15 Points: Highly effective and creative use of prompt engineering; results in relevant, high-quality content.
  10-12 Points: Good use of AI, generally aligns with content needs with minor issues.
  5-9 Points: Inconsistent effectiveness; prompt responses are somewhat relevant.
  0-4 Points: Ineffective use of prompt engineering with little relevance to the content.
  4. Writing Quality (15 Points)
  13-15 Points: Writing is clear, concise, and adheres to academic standards without grammatical errors.
  10-12 Points: Generally good writing quality, with few grammatical issues.
  5-9 Points: Several grammatical or stylistic errors; room for improvement.
  0-4 Points: Poor writing quality with numerous errors.
  
  5. Originality and Insight (10 Points)
  9-10 Points: Provides significant original thoughts and insightful analyses, offering unique perspectives or novel interpretations. Examples might include proposing new applications for LLMs, offering fresh ethical considerations, or novel comparisons of generative models.
  6-8 Points: Shows original thinking by presenting known information in new ways or linking concepts creatively. Offers fresh perspectives but does not fully explore new directions.
  3-5 Points: Limited originality, mostly restates known information with minimal new insights.
  0-2 Points: Entirely derivative, no original insights.
  
  6. Process Documentation and Evaluation of Prompt Techniques (25 Points)
  21-25 Points: Exceptional documentation of the prompting process, including detailed evaluations and comparisons, supported by relevant examples and evidence. Reflects deep understanding and critical analysis with in-depth discussions on each technique's effectiveness.
  16-20 Points: Good documentation with clear descriptions and evaluations, includes some comparative analysis and evidence, but lacks some depth in critical reflection.
  8-15 Points: Basic documentation, lacks depth in evaluations and comparative analysis, with minimal supporting evidence.
  0-7 Points: Inadequate documentation, minimal or no descriptions of processes, lacks critical evaluation.
  
  This expanded rubric should better guide the assessment of students' work, emphasizing critical evaluation and original thought in their academic exploration.
  
  
  
  
  Example 2:
  Here is a structured rubric for an AI-powered application project. It will focus on the thorough understanding and holistic effort of students, with special attention to the data collection process and the diversity of bot functionalities. Additionally, creativity in solution design and utility, along with comprehensive evaluation, will be key aspects.
  
  Point Allocation:
  Data Collection and Bot Functionality: 40 points
  Creativity and Solution Utility: 30 points
  Evaluation and Testing Process: 20 points
  Professionalism: 10 points
  
  Detailed Rubric:
  1. Data Collection and Bot Functionality (40 Points)
  35-40 Points: Exceptional variety in data collection sources and methods; the bot can perform complex and varied actions on the data that demonstrate deep integration and understanding.
  25-34 Points: Good variety and integration, but actions are somewhat basic or expected.
  0-24 Points: Limited data sources, minimal variety in bot actions, or poor integration of data with bot functionalities.
  
  2. Creativity and Solution Utility (30 Points)
  25-30 Points: Highly unique and useful application that solves a distinct problem, not commonly seen in existing tutorials; shows thoughtful backend AI development.
  15-24 Points: Some creative elements and utility but lacks uniqueness or substantial backend complexity.
  0-14 Points: Common solution with little creativity or practical usefulness.
  
  3. Evaluation and Testing Process (20 Points)
  17-20 Points: Thorough and well-documented testing and evaluation process; demonstrates understanding and addresses potential issues with detailed testing.
  10-16 Points: Adequate testing but lacks depth or comprehensive evaluation.
  0-9 Points: Minimal or superficial testing and evaluation.
  
  4. Professionalism (10 Points)
  9-10 Points: Code is well-documented and easy to understand; comprehensive README with appropriate licensing, correct source citations, and a professionally structured report.
  5-8 Points: Generally well-documented, minor issues in readability or completeness.
  0-4 Points: Lacks sufficient documentation or professional presentation.
  
  This rubric aims to reward students for exceptional understanding, creativity, and thorough evaluation, while ensuring that the basic requirements are met for a solid foundational score.
  
  
  
  
  Example 3:
  Given your scoring criteria and the distribution of emphasis across different aspects of the project, here's how we might allocate the 100 points across the categories:
  
  Point Allocation:
  Justification of Technology Choices: 10 points
  Fine-Tuning of the LLM and Performance Analysis: 40 points
  Creativity: 25 points
  Professionalism in Presentation and Code: 25 points
  
  Detailed Rubric:
  1. Justification of Technology Choices (10 Points)
  8-10 Points: Clear, concise, and logical explanations connecting technology choices to project needs.
  5-7 Points: Adequate explanation with minor gaps in logic or relevance.
  0-4 Points: Poorly explained or irrelevant justifications.
  
  2. Fine-Tuning of the LLM and Performance Analysis (40 Points)
  35-40 Points: Comprehensive and detailed process with a variety of training data, robust evaluation on new data, insightful performance analysis, clearly articulated challenges and well-considered future improvements.
  25-34 Points: Good detail and logical process, but may lack depth in performance analysis or suggestions for future work.
  0-24 Points: Inadequate detail, missing steps, unclear reasoning, or minimal analysis of challenges and improvements.
  
  3. Creativity (25 Points)
  20-25 Points: Demonstrates exceptional creativity in approach, problem-solving, and/or application features; goes well beyond the basic requirements.
  15-19 Points: Shows some creative elements but does not extensively explore new ideas or approaches.
  0-14 Points: Little to no creativity or original thought in project execution.
  
  4. Professionalism in Presentation and Code (25 Points)
  20-25 Points: Impeccable code documentation and comments, comprehensive README with appropriate licensing, proper source citation, and a professionally written report.
  15-19 Points: Generally well-documented and structured, minor issues in readability or completeness.
  0-14 Points: Lacks sufficient documentation, unclear or incomplete README, poor structure in the report, or missing citations.
  This rubric ensures that students are rewarded for both meeting the basic requirements and for demonstrating exceptional skill or understanding in key areas.

  """

  return context
